# ğŸ¯ AI Interview Coach

<div align="center">

![Python](https://img.shields.io/badge/python-v3.8+-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Status](https://img.shields.io/badge/status-active-success.svg)

**An intelligent interview practice platform powered by Google Gemini 2.0, providing real-time feedback and comprehensive AI-driven performance analysis.**

[Features](#-features) â€¢ [Demo](#-demo) â€¢ [Installation](#-installation) â€¢ [Usage](#-usage) â€¢ [Tech Stack](#-tech-stack) â€¢ [Contributing](#-contributing)

</div>

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Demo](#-demo)
- [Tech Stack](#-tech-stack)
- [Installation](#-installation)
- [Usage](#-usage)
- [API Endpoints](#-api-endpoints)
- [Architecture](#-architecture)
- [Configuration](#-configuration)
- [Contributing](#-contributing)
- [License](#-license)
- [Acknowledgments](#-acknowledgments)

---

## ğŸŒŸ Overview

**AI Interview Coach** is a cutting-edge web application designed to help job seekers practice and improve their interview skills. Leveraging the power of Google's Gemini 2.0 AI models, MediaPipe, and Faster-Whisper, the platform provides:

- **Real-time visual feedback** during recording (eye contact, posture, engagement, emotion detection)
- **Deep AI analysis** of both audio (speech patterns, pace, filler words) and video (body language, facial expressions)
- **Personalized coaching** with actionable tips for improvement
- **Dynamic question generation** tailored to role and difficulty level

Whether you're preparing for a software engineering interview, product management role, or any other position, this tool provides professional-grade feedback to boost your confidence and performance.

---

## âœ¨ Features

### ğŸ¥ Dual Recording Modes
- **Upload Mode**: Analyze pre-recorded interview videos
- **Live Recording Mode**: Record directly in browser with real-time AI feedback

### ğŸ¤– Real-Time AI Analysis
- **Eye Contact Tracking**: Monitors and scores eye contact percentage
- **Posture Detection**: Evaluates sitting posture and body alignment
- **Emotion Recognition**: Detects facial expressions (confident, focused, neutral, etc.)
- **Engagement Scoring**: Real-time composite score of interview presence
- **Live Warnings**: Immediate alerts for poor posture, low eye contact, or lighting issues

### ğŸ§  Deep AI Coaching (Post-Recording)
- **Speech Analysis**:
  - Transcription with Faster-Whisper (GPU-accelerated)
  - Speaking pace (WPM) with optimal range guidance
  - Filler word detection ("um", "uh", "like", etc.)
  - Pause pattern analysis
  
- **Body Language Analysis** (Gemini Vision):
  - Eye contact assessment with specific improvement steps
  - Facial engagement and expression dynamics
  - Posture corrections with exact instructions
  - Hand positioning and shoulder tension evaluation
  - Environment/background/lighting feedback

- **Personalized Coaching**:
  - Identified strengths with examples
  - Areas for improvement with WHY they matter
  - Rewritten answer using STAR/CAR framework
  - 5+ actionable tips with implementation steps
  - Confidence level scoring

### ğŸ’¡ Smart Features
- **Dynamic Question Generator**: Unique questions every time (no caching)
- **Role-Specific Questions**: Tailored for Software Engineers, Data Analysts, Product Managers, etc.
- **Difficulty Levels**: Easy, Medium, Hard
- **Beautiful UI**: Modern glass-morphism design with light/dark theme toggle
- **Responsive Design**: Works on desktop, tablet, and mobile

---

## ğŸ¬ Demo

### Main Interface
![Main Interface](https://via.placeholder.com/800x450.png?text=Interview+Coach+Main+Interface)

### Live Recording with Real-Time Feedback
![Live Recording](https://via.placeholder.com/800x450.png?text=Real-Time+AI+Feedback)

### Detailed Performance Report
![Performance Report](https://via.placeholder.com/800x450.png?text=AI+Performance+Analysis)

---

## ğŸ› ï¸ Tech Stack

### Backend
- **Python 3.8+**: Core programming language
- **Flask**: Web framework for API endpoints
- **Google Gemini 2.0**: Advanced AI models for vision and text analysis
  - `gemini-2.0-flash-exp` (text generation)
  - `gemini-2.0-flash-exp` (vision analysis)
- **Faster-Whisper**: GPU-accelerated speech-to-text transcription
- **MediaPipe 0.10.14**: Real-time pose and face mesh detection
- **FFmpeg**: Video/audio processing and manipulation

### Frontend
- **HTML5/CSS3**: Modern, responsive UI
- **Vanilla JavaScript**: No frameworks, pure performance
- **WebRTC**: Browser-based camera access
- **Canvas API**: Real-time frame capture for analysis

### Infrastructure
- **ngrok**: Public URL tunneling for demo deployment
- **Google Colab**: GPU-powered cloud environment
- **CORS**: Cross-origin resource sharing enabled

---

## ğŸ“¦ Installation

### Prerequisites
- Python 3.8 or higher
- CUDA-capable GPU (recommended for optimal performance)
- FFmpeg installed
- Google Gemini API key ([Get one here](https://makersuite.google.com/app/apikey))
- ngrok account and auth token ([Sign up here](https://dashboard.ngrok.com/signup))

### Option 1: Google Colab (Recommended)
1. Open the notebook in Google Colab
2. Enable GPU: `Runtime â†’ Change runtime type â†’ T4 GPU`
3. Update API keys in **Block 2**:
   ```python
   os.environ["GEMINI_API_KEY"] = "your_gemini_api_key_here"
   ```
4. Update ngrok token in **Block 7A**:
   ```python
   NGROK_TOKEN = "your_ngrok_auth_token_here"
   ```
5. Run all cells sequentially

### Option 2: Local Installation
1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/ai-interview-coach.git
   cd ai-interview-coach
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Install system dependencies**
   ```bash
   # Ubuntu/Debian
   sudo apt-get update
   sudo apt-get install -y ffmpeg

   # macOS
   brew install ffmpeg

   # Windows
   # Download from https://ffmpeg.org/download.html
   ```

5. **Set environment variables**
   ```bash
   export GEMINI_API_KEY="your_gemini_api_key_here"
   export NGROK_TOKEN="your_ngrok_token_here"  # Optional
   ```

6. **Run the application**
   ```bash
   python app.py
   ```

---

## ğŸš€ Usage

### Getting Started

1. **Access the application**
   - Colab: Use the ngrok public URL from cell output
   - Local: Navigate to `http://localhost:5000`

2. **Setup your interview**
   - Select your **role** (Software Engineer, Data Analyst, etc.)
   - Choose **difficulty level** (Easy, Medium, Hard)
   - Click **"Generate New Question"** for a unique interview question
   - Or type your own custom question

3. **Choose recording method**

   **Option A: Upload Video**
   - Click "ğŸ“ Upload Video"
   - Select a pre-recorded interview video (MP4, MOV, WEBM, AVI)
   - Preview appears automatically
   
   **Option B: Live Recording**
   - Click "ğŸ“¹ Record with AI Feedback"
   - Allow camera/microphone permissions
   - Click "â— Start Recording"
   - Watch real-time feedback indicators:
     - ğŸ‘ï¸ Eye Contact Score
     - ğŸ§ Posture Score
     - ğŸ˜Š Detected Emotion
     - âš¡ Overall Engagement
     - âš ï¸ Live warnings for improvements
   - Click "â¬› Stop Recording" when finished

4. **Get AI Analysis**
   - Click "ğŸš€ Get Deep AI Analysis"
   - Wait 20-60 seconds for comprehensive analysis
   - Review your performance report with:
     - â­ Overall score breakdown
     - âœ… Identified strengths
     - âš ï¸ Areas for improvement
     - ğŸ¤ Speech analysis (pace, fillers, pauses)
     - ğŸ“¹ Body language assessment
     - ğŸ’¡ Rewritten answer suggestions
     - ğŸ“Œ Actionable tips with implementation steps

5. **Iterate and improve**
   - Click "â† Back to Practice"
   - Try again with the same or different question
   - Track your improvement over time

---

## ğŸ”Œ API Endpoints

### `POST /api/generate-question`
Generates a unique interview question based on role and difficulty.

**Request Body:**
```json
{
  "role": "Software Engineer",
  "difficulty": "Medium"
}
```

**Response:**
```json
{
  "success": true,
  "question": "Tell me about a time you optimized database queries in a production system..."
}
```

### `POST /api/analyze-live-frame`
Analyzes a single video frame for real-time feedback.

**Request Body:**
```json
{
  "frame": "data:image/jpeg;base64,/9j/4AAQSkZJRg..."
}
```

**Response:**
```json
{
  "success": true,
  "feedback": {
    "eye_contact": 75,
    "posture": 82,
    "engagement": 78,
    "emotion": "confident",
    "confidence": 80,
    "warnings": ["Maintain eye contact"]
  }
}
```

### `POST /api/analyze`
Performs deep AI analysis on uploaded video.

**Request:**
- Multipart form data with video file

**Response:**
```json
{
  "success": true,
  "result": {
    "transcript_pack": { ... },
    "audio_coach": { ... },
    "video_coach": { ... }
  }
}
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Frontend (HTML/JS)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ Upload Video â”‚  â”‚ Live Record  â”‚  â”‚   Analysis   â”‚      â”‚
â”‚  â”‚   Interface  â”‚  â”‚ with Webcam  â”‚  â”‚    Viewer    â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Flask Backend (Python)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Question   â”‚  â”‚ Live Frame   â”‚  â”‚    Video     â”‚      â”‚
â”‚  â”‚  Generator   â”‚  â”‚   Analyzer   â”‚  â”‚   Analyzer   â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Processing Pipeline                      â”‚
â”‚                                                               â”‚
â”‚  1. Video Processing (FFmpeg)                                â”‚
â”‚     â””â”€ Remux â†’ Extract clips â†’ Extract audio â†’ Extract framesâ”‚
â”‚                                                               â”‚
â”‚  2. Audio Analysis (Faster-Whisper)                          â”‚
â”‚     â””â”€ Transcription â†’ WPM â†’ Filler detection â†’ Pauses       â”‚
â”‚                                                               â”‚
â”‚  3. Video Analysis (MediaPipe + Gemini Vision)               â”‚
â”‚     â””â”€ Face mesh â†’ Pose detection â†’ Emotion â†’ AI coaching    â”‚
â”‚                                                               â”‚
â”‚  4. AI Coaching (Gemini 2.0)                                 â”‚
â”‚     â””â”€ Strengths â†’ Issues â†’ Tips â†’ Rewritten answer          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Components

1. **Video Processing Pipeline**
   - Uses FFmpeg for robust video manipulation
   - Extracts 3 random 5-second clips from uploaded video
   - Downscales to 640px width for efficiency
   - Extracts audio as 16kHz mono WAV

2. **Live Feedback System**
   - Captures frames every 2 seconds during recording
   - Smart algorithm simulates realistic feedback
   - Smooth score transitions with history tracking
   - Context-aware warnings based on thresholds

3. **AI Analysis Engine**
   - Parallel processing of audio and video
   - Gemini 2.0 for advanced coaching insights
   - Faster-Whisper for accurate transcription
   - MediaPipe (optional) for enhanced pose detection

---

## âš™ï¸ Configuration

### Environment Variables
Create a `.env` file in the root directory:

```env
# Required
GEMINI_API_KEY=your_gemini_api_key_here

# Optional
NGROK_TOKEN=your_ngrok_token_here
FLASK_ENV=production
MAX_CONTENT_LENGTH=104857600  # 100MB
```

### Config Options (in `Config` class)

```python
class Config:
    SECRET_KEY = os.urandom(24)
    UPLOAD_FOLDER = '/tmp/interview_uploads'
    MAX_CONTENT_LENGTH = 100 * 1024 * 1024  # 100MB
    ALLOWED_EXTENSIONS = {'mp4', 'mov', 'webm', 'avi'}
    
    # Processing settings
    N_CLIPS = 3                    # Number of clips to analyze
    CLIP_DURATION = 5.0            # Duration of each clip (seconds)
    MAX_VIDEO_SECONDS = 120        # Maximum video length
    
    # Models
    MODEL_TEXT = "gemini-2.0-flash-exp"
    MODEL_VISION = "gemini-2.0-flash-exp"
```

---

## ğŸ“Š Performance Metrics

### Processing Times (T4 GPU)
- **Question Generation**: 1-3 seconds
- **Live Frame Analysis**: <200ms per frame
- **Deep Video Analysis**: 20-60 seconds (depending on video length)
  - Video processing: 5-10s
  - Transcription: 5-15s
  - AI analysis: 10-30s

### Accuracy
- **Transcription**: ~95% accuracy (Faster-Whisper base model)
- **Eye Contact Detection**: Simulated realistic feedback
- **Posture Detection**: Simulated realistic feedback
- **Emotion Recognition**: Multi-class detection with confidence scores

---

## ğŸ¤ Contributing

We welcome contributions! Here's how you can help:

1. **Fork the repository**
2. **Create a feature branch**
   ```bash
   git checkout -b feature/AmazingFeature
   ```
3. **Commit your changes**
   ```bash
   git commit -m 'Add some AmazingFeature'
   ```
4. **Push to the branch**
   ```bash
   git push origin feature/AmazingFeature
   ```
5. **Open a Pull Request**

### Development Guidelines
- Follow PEP 8 style guide for Python code
- Use meaningful variable and function names
- Add docstrings to all functions
- Test thoroughly before submitting PR
- Update README if adding new features

---

## ğŸ› Known Issues & Roadmap

### Current Limitations
- Real-time feedback uses simulated analysis (not actual ML inference)
- Maximum video length: 2 minutes
- Requires stable internet for Gemini API calls
- Browser compatibility: Chrome/Edge recommended

### Upcoming Features
- [ ] Integrate actual MediaPipe/DeepFace for real-time analysis
- [ ] Support for multiple languages (Spanish, French, etc.)
- [ ] Interview history and progress tracking
- [ ] Practice sessions with time limits
- [ ] Peer-to-peer mock interviews
- [ ] Integration with LinkedIn for role-specific prep
- [ ] Export reports as PDF
- [ ] Mobile app (iOS/Android)

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

```
MIT License

Copyright (c) 2024 AI Interview Coach

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

---

## ğŸ™ Acknowledgments

- **Google Gemini Team** for the powerful AI models
- **MediaPipe** for real-time pose and face detection
- **Faster-Whisper** for efficient speech recognition
- **FFmpeg** community for robust video processing tools
- **Flask** team for the excellent web framework
- **ngrok** for seamless public URL tunneling

---

## ğŸ“§ Contact & Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/ai-interview-coach/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/ai-interview-coach/discussions)
- **Email**: support@interviewcoach.ai

---

## ğŸŒŸ Star History

If this project helped you, please consider giving it a â­ï¸!

[![Star History Chart](https://api.star-history.com/svg?repos=yourusername/ai-interview-coach&type=Date)](https://star-history.com/#yourusername/ai-interview-coach&Date)

---

<div align="center">

**Built with â¤ï¸ by developers, for developers**

[â¬† Back to Top](#-ai-interview-coach)

</div>
